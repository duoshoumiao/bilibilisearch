import os
import json
import re
import time
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, List
from urllib.parse import quote

from hoshino import Service, priv
from hoshino.typing import CQEvent
import aiohttp

# ä¸»æœåŠ¡å®šä¹‰
sv = Service('bç«™è§†é¢‘æœç´¢', enable_on_default=True, help_='æœç´¢Bç«™è§†é¢‘\nä½¿ç”¨æ–¹æ³•ï¼š\n1. æŸ¥è§†é¢‘ [å…³é”®è¯/åç§°-up] - æœç´¢Bç«™è§†é¢‘\n2. è§†é¢‘å…³æ³¨/å…³æ³¨+ [è§†é¢‘é“¾æ¥] - é€šè¿‡è§†é¢‘é“¾æ¥å…³æ³¨UPä¸»\n3. å–å…³up [UPä¸»åç§°] - å–æ¶ˆç›‘æ§\n4. æŸ¥çœ‹å…³æ³¨ - æŸ¥çœ‹å½“å‰ç›‘æ§åˆ—è¡¨')

# é…ç½®é¡¹
MAX_RESULTS = 5
UP_WATCH_INTERVAL = 5  # ç›‘æ§é—´éš”(åˆ†é’Ÿ)
CACHE_EXPIRE_MINUTES = 3
search_cache = {}

# JSONå­˜å‚¨æ–‡ä»¶è·¯å¾„
WATCH_JSON_PATH = Path(__file__).parent / 'data' / 'bili_watch.json'
os.makedirs(WATCH_JSON_PATH.parent, exist_ok=True)

# è¾…åŠ©å‡½æ•°å®šä¹‰
def normalize_name(name: str) -> str:
    """æ ‡å‡†åŒ–åç§°(å»å‰åç©ºæ ¼/å°å†™)"""
    return name.strip().lower()

def process_pic_url(pic_url: str) -> str:
    """å¤„ç†å›¾ç‰‡URL"""
    if not pic_url:
        return ""
    if not pic_url.startswith(('http://', 'https://')):
        pic_url = 'https:' + pic_url
    return f'https://images.weserv.nl/?url={quote(pic_url.split("//")[-1])}&w=800&h=450'

class UpWatchStorage:
    def __init__(self):
        self._data = {}  # ä¸»æ•°æ®ç»“æ„: {group_id: {up_name: {last_check, last_vid}}}
        self.name_index = {}  # åç§°å°å†™ç´¢å¼•: {up_name_lower: {group_id: up_name}}
        self._load_data()
        sv.logger.info("UPä¸»ç›‘æ§å­˜å‚¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            if WATCH_JSON_PATH.exists():
                with open(WATCH_JSON_PATH, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # éªŒè¯å¹¶è½¬æ¢æ•°æ®æ ¼å¼
                    if isinstance(data, dict):
                        self._data = {}
                        for group_id_str, ups in data.items():
                            if not isinstance(ups, dict):
                                continue
                            self._data[group_id_str] = {}
                            for up_name, info in ups.items():
                                if not isinstance(info, dict):
                                    continue
                                self._data[group_id_str][up_name] = {
                                    'last_check': info.get('last_check', datetime.now().isoformat()),
                                    'last_vid': info.get('last_vid')
                                }
                                # æ›´æ–°åç§°ç´¢å¼•
                                up_name_lower = normalize_name(up_name)
                                if up_name_lower not in self.name_index:
                                    self.name_index[up_name_lower] = {}
                                self.name_index[up_name_lower][group_id_str] = up_name
        except Exception as e:
            sv.logger.error(f"åŠ è½½ç›‘æ§æ•°æ®å¤±è´¥: {str(e)}")
            self._data = {}
            self.name_index = {}
    
    def save(self):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with open(WATCH_JSON_PATH, 'w', encoding='utf-8') as f:
                json.dump(self._data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            sv.logger.error(f"ä¿å­˜ç›‘æ§æ•°æ®å¤±è´¥: {str(e)}")
    
    def add_watch(self, group_id: int, up_name: str, last_vid: str = None):
        """æ·»åŠ ç›‘æ§"""
        group_id = str(group_id)
        if group_id not in self._data:
            self._data[group_id] = {}
        
        self._data[group_id][up_name] = {
            'last_check': datetime.now().isoformat(),
            'last_vid': last_vid
        }
        
        # æ›´æ–°åç§°ç´¢å¼•
        up_name_lower = normalize_name(up_name)
        if up_name_lower not in self.name_index:
            self.name_index[up_name_lower] = {}
        self.name_index[up_name_lower][group_id] = up_name
        
        self.save()
        sv.logger.info(f"å·²æ·»åŠ ç›‘æ§: ç¾¤{group_id} -> UPä¸»{up_name}")
    
    def remove_watch(self, group_id: int, up_name: str) -> bool:
        """ç§»é™¤ç›‘æ§ï¼ˆä»…ç§»é™¤å½“å‰ç¾¤çš„ç›‘æ§ï¼‰"""
        group_id = str(group_id)
        up_name_lower = normalize_name(up_name)
        
        # æ£€æŸ¥å½“å‰ç¾¤æ˜¯å¦ç›‘æ§äº†è¯¥UPä¸»
        if group_id in self._data and up_name in self._data[group_id]:
            # åˆ é™¤ä¸»æ•°æ®
            del self._data[group_id][up_name]
            if not self._data[group_id]:  # å¦‚æœç¾¤ç›‘æ§åˆ—è¡¨ä¸ºç©ºï¼Œåˆ é™¤æ•´ä¸ªç¾¤æ¡ç›®
                del self._data[group_id]
            
            # æ›´æ–°åç§°ç´¢å¼•
            if up_name_lower in self.name_index and group_id in self.name_index[up_name_lower]:
                del self.name_index[up_name_lower][group_id]
                if not self.name_index[up_name_lower]:  # å¦‚æœè¯¥UPä¸»æ²¡æœ‰è¢«ä»»ä½•ç¾¤ç›‘æ§ï¼Œåˆ é™¤æ•´ä¸ªç´¢å¼•
                    del self.name_index[up_name_lower]
            
            self.save()
            sv.logger.info(f"å·²ç§»é™¤ç›‘æ§: ç¾¤{group_id} -> UPä¸»{up_name}")
            return True
        
        sv.logger.warning(f"ç§»é™¤ç›‘æ§å¤±è´¥: ç¾¤{group_id} æœªç›‘æ§ UPä¸»{up_name}")
        return False
    
    def get_group_watches(self, group_id: int) -> Dict[str, Dict[str, Any]]:
        """è·å–ç¾¤ç»„ç›‘æ§åˆ—è¡¨"""
        group_id = str(group_id)
        return self._data.get(group_id, {})
    
    def get_all_watches(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰ç›‘æ§æ•°æ®"""
        return self._data
    
    def update_last_video(self, group_id: int, up_name: str, last_vid: str):
        """æ›´æ–°æœ€åè§†é¢‘è®°å½•"""
        group_id = str(group_id)
        if group_id in self._data and up_name in self._data[group_id]:
            self._data[group_id][up_name].update({
                'last_vid': last_vid,
                'last_check': datetime.now().isoformat()
            })
            self.save()
    
    def find_up_by_name(self, name: str) -> Dict[str, str]:
        """é€šè¿‡åç§°æŸ¥æ‰¾UPä¸»"""
        return self.name_index.get(normalize_name(name), {})

# å…¨å±€å­˜å‚¨å®ä¾‹
watch_storage = UpWatchStorage()

def normalize_name(name: str) -> str:
    """æ ‡å‡†åŒ–åç§°(å»å‰åç©ºæ ¼/å°å†™)"""
    return name.strip().lower()

def process_pic_url(pic_url: str) -> str:
    """å¤„ç†å›¾ç‰‡URL"""
    if not pic_url:
        return ""
    if not pic_url.startswith(('http://', 'https://')):
        pic_url = 'https:' + pic_url
    return f'https://images.weserv.nl/?url={quote(pic_url.split("//")[-1])}&w=800&h=450'

async def get_video_info(bvid: str) -> Optional[Dict]:
    """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
        'Referer': f'https://www.bilibili.com/video/{bvid}'
    }
    url = f'https://api.bilibili.com/x/web-interface/view?bvid={bvid}'
    
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url, headers=headers, timeout=10) as resp:
                if resp.status != 200:
                    sv.logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: HTTP {resp.status}")
                    return None
                data = await resp.json()
                if data.get('code') == 0:
                    return data['data']
                sv.logger.error(f"è§†é¢‘APIè¿”å›é”™è¯¯: {data.get('message')}")
        except Exception as e:
            sv.logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¼‚å¸¸: {str(e)}")
    return None

async def get_bilibili_search(keyword: str, search_type: str = "video") -> List[Dict]:
    """ç»Ÿä¸€æœç´¢å‡½æ•°"""
    cache_key = f"{search_type}:{normalize_name(keyword)}"
    if cache_key in search_cache:
        cached_data, timestamp = search_cache[cache_key]
        if datetime.now() - timestamp < timedelta(minutes=CACHE_EXPIRE_MINUTES):
            return cached_data[:MAX_RESULTS]

    params = {
        'search_type': 'video',
        'keyword': keyword,
        'order': 'pubdate' if search_type == "up" else 'totalrank',
        'ps': MAX_RESULTS * 2,
        'platform': 'web'
    }

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
        'Referer': 'https://www.bilibili.com/',
        'Cookie': 'buvid3=XXXXXX;'
    }

    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(
                'https://api.bilibili.com/x/web-interface/search/type',
                params=params,
                headers=headers,
                timeout=10
            ) as resp:
                if resp.status != 200:
                    sv.logger.error(f"æœç´¢è¯·æ±‚å¤±è´¥: HTTP {resp.status}")
                    return []
                
                data = await resp.json()
                if data.get('code') == 0:
                    raw_results = data['data'].get('result', [])
                    # ç²¾ç¡®ç­›é€‰ç»“æœ
                    results = []
                    for video in raw_results:
                        if len(results) >= MAX_RESULTS:
                            break
                        # UPä¸»æœç´¢æ¨¡å¼éœ€è¦ä½œè€…åŒ¹é…
                        if search_type == "up" and normalize_name(video.get('author', '')) != normalize_name(keyword):
                            continue
                        results.append(video)
                    
                    search_cache[cache_key] = (results, datetime.now())
                    return results
                sv.logger.error(f"APIè¿”å›é”™è¯¯: {data.get('message')}")
        except Exception as e:
            sv.logger.error(f"æœç´¢å¤±è´¥: {str(e)}")
    return []

async def safe_send(bot, ev, message):
    """å®‰å…¨å‘é€æ¶ˆæ¯"""
    try:
        if not message:
            return
            
        if isinstance(message, list):
            message = '\n'.join(message)
            
        await bot.send(ev, message)
    except Exception as e:
        sv.logger.error(f'å‘é€æ¶ˆæ¯å¤±è´¥: {str(e)}')

@sv.on_prefix(('è§†é¢‘å…³æ³¨','å…³æ³¨'))
async def watch_by_video(bot, ev: CQEvent):
    """é€šè¿‡è§†é¢‘é“¾æ¥å…³æ³¨UPä¸»"""
    video_url = ev.message.extract_plain_text().strip()
    if not video_url:
        await bot.send(ev, 'è¯·è¾“å…¥è§†é¢‘é“¾æ¥ï¼Œä¾‹å¦‚ï¼šè§†é¢‘å…³æ³¨ https://www.bilibili.com/video/BV1B73kzcE1e')
        return
    
    # æå–BVå·
    bvid = None
    patterns = [
        r'bilibili\.com/video/(BV[0-9A-Za-z]+)',
        r'b23\.tv/(BV[0-9A-Za-z]+)',
        r'(BV[0-9A-Za-z]+)',
        r'bilibili\.com/video/av\d+\?.*bv=(BV[0-9A-Za-z]+)',
        r'video/(BV[0-9A-Za-z]+)/?'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, video_url)
        if match:
            bvid = match.group(1)
            break
    
    if not bvid:
        await bot.send(ev, 'âš ï¸ æ— æ³•è¯†åˆ«è§†é¢‘BVå·ï¼Œè¯·ç¡®è®¤é“¾æ¥æ ¼å¼æ­£ç¡®\n'
                         'ğŸ“Œ æ”¯æŒæ ¼å¼ç¤ºä¾‹:\n'
                         '1. https://www.bilibili.com/video/BV1B73kzcE1e\n'
                         '2. https://b23.tv/BV1B73kzcE1e\n'
                         '3. BV1B73kzcE1e')
        return
    
    group_id = ev.group_id
    
    try:
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = await get_video_info(bvid)
        if not video_info:
            await bot.send(ev, 'âŒ è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥BVå·æ˜¯å¦æ­£ç¡®æˆ–ç¨åå†è¯•')
            return
        
        up_name = video_info['owner']['name']
        
        # æ£€æŸ¥æœ¬ç¾¤æ˜¯å¦å·²å…³æ³¨
        group_watches = watch_storage.get_group_watches(group_id)
        if up_name in group_watches:
            last_check = datetime.fromisoformat(group_watches[up_name]['last_check']).strftime('%m-%d %H:%M')
            await bot.send(ev, f'â„¹ï¸ æœ¬ç¾¤å·²å…³æ³¨ã€{up_name}ã€‘\n'
                             f'â° æœ€åæ£€æŸ¥æ—¶é—´: {last_check}')
            return
        
        # æ·»åŠ åˆ°æœ¬ç¾¤ç›‘æ§
        watch_storage.add_watch(
            group_id=group_id,
            up_name=up_name,
            last_vid=bvid
        )
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        pub_time = datetime.fromtimestamp(video_info['pubdate']).strftime('%Y-%m-%d %H:%M')
        pic_url = process_pic_url(video_info['pic'])
        
        msg = [
            f'âœ… æˆåŠŸå…³æ³¨UPä¸»ã€{up_name}ã€‘',
            f'ğŸ“º è§†é¢‘æ ‡é¢˜: {video_info["title"]}',
            f'[CQ:image,file={pic_url}]',
            f'â° å‘å¸ƒæ—¶é—´: {pub_time}',
            f'ğŸ”— è§†é¢‘é“¾æ¥: https://b23.tv/{bvid}',
            'ğŸ“¢ è¯¥UPä¸»çš„æ–°è§†é¢‘å°†ä¼šé€šçŸ¥æœ¬ç¾¤'
        ]
        
        await bot.send(ev, '\n'.join(msg))
        
    except aiohttp.ClientError as e:
        await bot.send(ev, f'ğŸŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}\nè¯·ç¨åå†è¯•')
    except json.JSONDecodeError:
        await bot.send(ev, 'âŒ æ•°æ®è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯Bç«™APIå˜æ›´\nè¯·é€šçŸ¥ç»´æŠ¤äººå‘˜æ£€æŸ¥')
    except Exception as e:
        sv.logger.error(f'è§†é¢‘å…³æ³¨åŠŸèƒ½å¼‚å¸¸: {type(e).__name__}: {str(e)}')
        await bot.send(ev, f'âš ï¸ å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}\nè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯')

@sv.on_prefix(('å–å…³up','å–å…³'))
async def unwatch_bilibili_up(bot, ev: CQEvent):
    """å–å…³æŒ‡å®šUPä¸»ï¼ˆä»…å½“å‰ç¾¤ï¼‰"""
    up_name = ev.message.extract_plain_text().strip()
    group_id = ev.group_id
    
    # æŸ¥æ‰¾å‡†ç¡®çš„UPä¸»åç§°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    found = watch_storage.find_up_by_name(up_name)
    if not found or str(group_id) not in found:
        await bot.send(ev, f'æœ¬ç¾¤æœªç›‘æ§ã€{up_name}ã€‘')
        return
    
    # è·å–å‡†ç¡®çš„UPä¸»åç§°ï¼ˆä¿ç•™å¤§å°å†™ï¼‰
    exact_name = found[str(group_id)]
    
    if watch_storage.remove_watch(group_id, exact_name):
        await bot.send(ev, f'âœ… å·²å–æ¶ˆå¯¹ã€{exact_name}ã€‘çš„ç›‘æ§')
    else:
        await bot.send(ev, 'âŒ å–å…³å¤±è´¥ï¼Œè¯·ç¨åå†è¯•')

@sv.on_fullmatch('æŸ¥çœ‹å…³æ³¨')
async def list_watched_ups(bot, ev: CQEvent):
    """æŸ¥çœ‹å½“å‰ç¾¤ç›‘æ§çš„UPä¸»åˆ—è¡¨"""
    group_id = ev.group_id
    watches = watch_storage.get_group_watches(group_id)
    
    if not watches:
        await bot.send(ev, 'å½“å‰æ²¡æœ‰ç›‘æ§ä»»ä½•UPä¸»')
        return
    
    up_list = ["ğŸ“¢ å½“å‰ç›‘æ§çš„UPä¸»åˆ—è¡¨:", "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"]
    for up_name, info in watches.items():
        last_check = datetime.fromisoformat(info['last_check']).strftime('%m-%d %H:%M')
        up_list.append(f"ğŸ‘¤ {up_name} | æœ€åæ£€æŸ¥: {last_check}")
        up_list.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    await bot.send(ev, "\n".join(up_list))

@sv.scheduled_job('interval', minutes=UP_WATCH_INTERVAL)
async def check_up_updates():
    """å®šæ—¶æ£€æŸ¥UPä¸»æ›´æ–°"""
    sv.logger.info("å¼€å§‹æ‰§è¡ŒUPä¸»ç›‘æ§æ£€æŸ¥...")
    all_watches = watch_storage.get_all_watches()
    if not all_watches:
        sv.logger.info("å½“å‰æ²¡æœ‰ç›‘æ§ä»»ä½•UPä¸»")
        return
    
    bot = sv.bot
    update_count = 0
    
    for group_id_str, up_dict in all_watches.items():
        group_id = int(group_id_str)
        for up_name, info in up_dict.items():
            try:
                # æ·»åŠ å»¶è¿Ÿé˜²æ­¢è¯·æ±‚è¿‡äºé¢‘ç¹
                await asyncio.sleep(10)
                
                last_vid = info.get('last_vid')
                sv.logger.info(f"æ£€æŸ¥UPä¸»ã€{up_name}ã€‘æ›´æ–°ï¼Œä¸Šæ¬¡è®°å½•è§†é¢‘: {last_vid or 'æ— '}")                

                # é€šè¿‡ä¸Šæ¬¡ä¿å­˜çš„BVå·è·å–UPä¸»mid
                if last_vid:
                    video_info = await get_video_info(last_vid)
                    if not video_info:
                        sv.logger.warning(f"æ— æ³•è·å–ä¸Šæ¬¡è§†é¢‘ä¿¡æ¯: {last_vid}")
                        continue
                    
                    up_mid = video_info['owner']['mid']
                    
                    # è·å–UPä¸»ç©ºé—´æœ€æ–°è§†é¢‘
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
                        'Referer': f'https://space.bilibili.com/{up_mid}'
                    }
                    url = f'https://api.bilibili.com/x/space/arc/search?mid={up_mid}&ps=5&order=pubdate'
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, headers=headers, timeout=10) as resp:
                            if resp.status != 200:
                                sv.logger.error(f"è·å–UPä¸»ç©ºé—´å¤±è´¥: HTTP {resp.status}")
                                continue
                            data = await resp.json()
                            if data.get('code') != 0:
                                sv.logger.error(f"UPä¸»ç©ºé—´APIè¿”å›é”™è¯¯: {data.get('message')}")
                                continue
                            
                            vlist = data['data']['list']['vlist']
                            if not vlist:
                                sv.logger.info(f"UPä¸»ã€{up_name}ã€‘ç©ºé—´æ²¡æœ‰è§†é¢‘")
                                continue
                            
                            latest_video = vlist[0]
                            current_bvid = latest_video['bvid']
                            video_pub_time = datetime.fromtimestamp(latest_video['created'])
                            
                            # éªŒè¯æ˜¯å¦ä¸ºæ–°è§†é¢‘
                            is_new = False
                            reason = ""
                            
                            if not last_vid:
                                is_new = True
                                reason = "é¦–æ¬¡ç›‘æ§è¯¥UPä¸»"
                            else:
                                # æ£€æŸ¥BVå·æ˜¯å¦ç›¸åŒ
                                if current_bvid == last_vid:
                                    reason = "BVå·ç›¸åŒï¼Œè§†é¢‘æœªæ›´æ–°"
                                else:
                                    # è·å–ä¸Šæ¬¡è§†é¢‘ä¿¡æ¯
                                    last_video_info = await get_video_info(last_vid)
                                    if not last_video_info:
                                        reason = "æ— æ³•è·å–ä¸Šæ¬¡è§†é¢‘ä¿¡æ¯ï¼Œä¿å®ˆå¤„ç†ä¸æ¨é€"
                                    else:
                                        last_pub_time = datetime.fromtimestamp(last_video_info['pubdate'])
                                        # æ¯”è¾ƒå‘å¸ƒæ—¶é—´ï¼ˆå¢åŠ 2åˆ†é’Ÿç¼“å†²ï¼‰
                                        if video_pub_time > (last_pub_time + timedelta(minutes=2)):
                                            is_new = True
                                            reason = (f"æ–°è§†é¢‘å‘å¸ƒæ—¶é—´({video_pub_time}) > "
                                                     f"ä¸Šæ¬¡è§†é¢‘å‘å¸ƒæ—¶é—´({last_pub_time})")
                                        else:
                                            reason = "æ— æ–°å‘å¸ƒ(å‘å¸ƒæ—¶é—´æœªè¶…è¿‡é˜ˆå€¼)"
                            
                            sv.logger.info(f"æ›´æ–°åˆ¤æ–­: {reason}")
                            
                            # å¦‚æœæ˜¯æ–°è§†é¢‘åˆ™æ›´æ–°è®°å½•å¹¶æ¨é€
                            if is_new:
                                watch_storage.update_last_video(
                                    group_id=group_id,
                                    up_name=up_name,
                                    last_vid=current_bvid
                                )
                                
                                # å‡†å¤‡é€šçŸ¥å†…å®¹
                                pub_time = video_pub_time.strftime("%Y-%m-%d %H:%M")
                                pic_url = process_pic_url(latest_video['pic'])
                                
                                msg = [
                                    f"ğŸ“¢ğŸ“¢ UPä¸»ã€{up_name}ã€‘å‘å¸ƒäº†æ–°è§†é¢‘ï¼",
                                    f"ğŸ“ºğŸ“º æ ‡é¢˜: {latest_video['title']}",
                                    f"[CQ:image,file={pic_url}]",
                                    f"â°â°â° å‘å¸ƒæ—¶é—´: {pub_time}",
                                    f"ğŸ”—ğŸ”— è§†é¢‘é“¾æ¥: https://b23.tv/{current_bvid}"
                                ]
                                
                                await bot.send_group_msg(group_id=group_id, message="\n".join(msg))
                                update_count += 1
                                sv.logger.info(f"å·²å‘é€æ–°è§†é¢‘é€šçŸ¥: {up_name} - {latest_video['title']}")
                
            except Exception as e:
                sv.logger.error(f'ç›‘æ§UPä¸»ã€{up_name}ã€‘å¤±è´¥: {str(e)}')
                continue
    
    sv.logger.info(f"ç›‘æ§æ£€æŸ¥å®Œæˆï¼Œå…±æ£€æŸ¥ {sum(len(v) for v in all_watches.values())} ä¸ªUPä¸»ï¼Œå‘ç° {update_count} ä¸ªæ›´æ–°")

@sv.on_prefix('æŸ¥è§†é¢‘')
async def search_bilibili_video(bot, ev: CQEvent):
    """æœç´¢Bç«™è§†é¢‘"""
    raw_input = ev.message.extract_plain_text().strip()
    if not raw_input:
        await bot.send(ev, 'è¯·è¾“å…¥æœç´¢æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š\n1. æŸ¥è§†é¢‘ åŸç¥\n2. æŸ¥è§†é¢‘ è€ç•ªèŒ„-up')
        return
    
    # è§£æ-upå‚æ•°
    keyword = None
    up_name = None
    
    if '-up' in raw_input:
        parts = re.split(r'\s*-up\s*', raw_input, 1)
        if len(parts) > 0:
            keyword = parts[0].strip() if parts[0].strip() else None
        if len(parts) > 1:
            up_name = parts[1].strip()
        
        # å¤„ç†"è€ç•ªèŒ„-up"æƒ…å†µ
        if not up_name and keyword:
            up_name = keyword
            keyword = None
    else:
        keyword = raw_input
    
    try:
        msg_id = (await bot.send(ev, "ğŸ” æœç´¢ä¸­..."))['message_id']
        
        # è·å–æœç´¢ç»“æœ
        if up_name:
            results = await get_bilibili_search(up_name, "up")
            if not results:
                await bot.finish(ev, f'æœªæ‰¾åˆ°UPä¸»ã€{up_name}ã€‘çš„è§†é¢‘')
                return
        else:
            search_term = keyword if keyword is not None else raw_input
            results = await get_bilibili_search(search_term)
            if not results:
                await bot.finish(ev, f'æœªæ‰¾åˆ°"{search_term}"ç›¸å…³è§†é¢‘')
                return
        
        # æ„å»ºå›å¤
        reply = ["ğŸ“º æœç´¢ç»“æœï¼ˆæœ€å¤š5ä¸ªï¼‰ï¼š", "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"]
        for i, video in enumerate(results[:MAX_RESULTS], 1):
            clean_title = re.sub(r'<[^>]+>', '', video['title'])
            pub_time = time.strftime("%Y-%m-%d %H:%M", time.localtime(video['pubdate']))
            
            pic_url = process_pic_url(video['pic'])
            
            reply.extend([
                f"{i}. {clean_title}",
                f"[CQ:image,file={pic_url}]",
                f"   ğŸ“… {pub_time} | ğŸ‘¤ {video['author']}",
                f"   ğŸ”— https://b23.tv/{video['bvid']}",
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            ])
        
        await safe_send(bot, ev, "\n".join(reply))
        
    except Exception as e:
        await bot.send(ev, f'æœç´¢å¤±è´¥: {str(e)}')
